# 분산 캐싱

분산 캐싱은 애플리케이션 성능과 확장성을 향상시키기 위해 자주 액세스하는 데이터를 여러 캐시 서버에 저장하는 기술입니다. 로컬 캐싱과 달리 분산 캐싱은 분산 시스템의 여러 애플리케이션 인스턴스 또는 서비스 간에 캐시 일관성을 유지합니다.

주요 이점으로는 데이터베이스 부하 감소, 응답 시간 개선, 더 나은 수평적 확장성이 있습니다. 일반적인 구현으로는 Redis와 Memcached가 있으며, Redis는 추가 데이터 구조와 영속성 옵션을 제공합니다.

분산 캐싱을 구현할 때 주요 고려 사항으로는 캐시 일관성 모델(강한 일관성 vs 최종 일관성), 제거 정책(LRU, LFU, FIFO), 데이터 분할 전략이 있습니다. 분할을 위해서는 일반적으로 일관된 해싱이 사용되어 확장 이벤트 중 재분배를 최소화하면서 캐시 항목을 분산시킵니다.

캐시 무효화 전략은 필수적입니다 - 일반적인 접근 방식으로는 TTL 기반 만료, 쓰기 통과(캐시와 데이터베이스를 동시에 업데이트), 캐시 어사이드(애플리케이션이 캐시 채우기 관리)가 있습니다. 시스템 전체 캐시 무효화는 발행-구독 메커니즘이나 버전 관리 전략을 통해 구현할 수 있습니다.

마이크로서비스 아키텍처에서는 각 서비스가 일반적으로 자체 캐시 액세스를 관리하며, 데이터 소유권 경계에 대한 신중한 고려가 필요합니다. 전 세계적인 애플리케이션의 경우, 복제를 사용한 다중 지역 캐싱은 복잡성을 증가시키지만 사용자 지연 시간을 줄입니다. 적절한 모니터링과 관찰 가능성(적중/실패 비율, 메모리 사용량, 제거 비율)은 최적의 캐시 성능을 유지하는 데 중요합니다.